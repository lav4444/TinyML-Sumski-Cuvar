1. Biranje programske podrške
  - TensorFlow
  - TensorFlow Lite
  - TensorFlow Lite Micro
  - Google Colab

2. Učitavanje već prikupljenih podataka (audio isječaka)
  - provjerit dostojnost podataka
  - podijelit u TRAIN / VALIDATE / TEST
    - jel VALIDATE podskup od TEST?
  - potencijalno dodavanje/brisanje manje kvalitetnih uzoraka
    - funkcija koja će pronaći manje kvalitetne uzorke

3. Pretprocesiranje podataka
  - po defaultu svaki sample je dužine 3s, možemo se igrati i sa kraćim uzorcima (uz kombiniranje 3/5 uzoraka POS za zaključak POS)

4. Izgradnja i treniranje ML modela
  - Skaliranje vrijednosti 0-1 ?
  - Odabir tipa NN (Convonutional, Recurrent, ...)
    - eksperimentirat s arhitekturom i hiperparametrima (funkcija koja testira razne tipove i parametre)
  - TRENING: pratit accuracy, loss i validation_accuracy (epoches until overfitting)
  - GENERALIZATION: data augmentation, regularisation (dropout and weight regularisation)
    - pogledat predavanje iz predmeta Obrada Informacija na temu GENERALIZACIJE
  -MONITORING: Monitor training process using TensorBoard

5. Compiling and deployment
  - TensorFlow Lite Micro
  - Arduino IDE ?


(

ChatGPT
Certainly! Here's a general outline of how you can configure a neural network architecture for audio classification using TensorFlow:

Data Preprocessing:
Load audio samples from WAV files and extract features such as MFCCs (Mel-frequency cepstral coefficients) or spectrograms.
Split the dataset into training, validation, and test sets.
Convert labels into numerical format suitable for training (e.g., using one-hot encoding).

Model Architecture:
Input Layer: Input features (e.g., MFCCs or spectrograms) representing audio samples.
Convolutional Layers: Convolutional layers can capture spatial and temporal patterns in the audio data.
Pooling Layers: Pooling layers can downsample the feature maps and reduce computational complexity.
Flatten Layer: Flatten the feature maps into a 1D vector for input to the fully connected layers.
Fully Connected Layers: Dense layers can learn high-level representations of the audio features.
Output Layer: Output layer with softmax activation for multi-class classification (2 classes in your case: background and chainsaw).

Hyperparameters:
Learning Rate: The rate at which the model weights are updated during training.
Batch Size: The number of samples processed before updating the model weights.
Number of Epochs: The number of times the entire dataset is passed forward and backward through the neural network.
Dropout Rate: Dropout regularization can prevent overfitting by randomly dropping units during training.

Loss Function and Optimizer:
Use categorical cross-entropy loss for multi-class classification.
Select an appropriate optimizer such as Adam or RMSprop.

Training:
Compile the model with the chosen loss function, optimizer, and evaluation metrics.
Train the model on the training data and validate it on the validation data.
Monitor training performance and adjust hyperparameters as needed.

Evaluation:
Evaluate the trained model on the test set to assess its performance.
Calculate metrics such as accuracy, precision, recall, and F1-score.
Analyze any misclassifications and refine the model if necessary.

Deployment:
Once satisfied with the model's performance, deploy it for real-world inference on new audio samples.
)
