AUDIO SAMPLES:
- TYPE: raw PCM (Pulse-Code Modulation) data
- but saved on disc as .json
- total: 1446 samples of length (3s) [= > 72 min]
- each sample in json format has 48,000 values representing interval of 0.0625ms[sampling rate] (= 3,000 ms = 3s) -> 16000 Hz
- VALUES: 
  TRAIN - MAX: 32767, MIN: -32768, AVG: 0.01062720702448845
  TEST - MAX: 32767, MIN: -32768, AVG: -0.21955287814719143
  (im thinking of shuffling training and testing data together)

Interval: 3000.0, Count: 1421
Interval: 2043.375, Count: 2
Interval: 928.8125, Count: 2
Interval: 650.1875, Count: 1
Interval: 1114.5625, Count: 1
Interval: 835.9375, Count: 1
Interval: 1743.75, Count: 1
Interval: 557.25, Count: 1
Interval: 185.75, Count: 1
Interval: 1857.625, Count: 2
Interval: 1038.0625, Count: 1
Interval: 2322.0, Count: 2
Interval: 1021.6875, Count: 1
Interval: 2229.125, Count: 1
Interval: 1764.6875, Count: 2
Interval: 2786.375, Count: 1
Interval: 905.5625, Count: 1
Interval: 92.875, Count: 1
Interval: 1578.9375, Count: 2
Interval: 1486.0625, Count: 1

-Architecture Design:
Experiment with different architectures: Try adding more layers, changing the number of neurons in each layer, or adding different types of layers like Convolutional Neural Networks (CNNs) or Recurrent Neural Networks (RNNs) depending on the characteristics of your data.
Consider using CNNs: CNNs are particularly effective for processing spatial data like images and spectrograms. They can capture local patterns effectively and are commonly used in audio processing tasks.
Use regularization techniques: Techniques like dropout and batch normalization can help prevent overfitting, especially when dealing with large models or limited training data.
-Hyperparameter Tuning:
Experiment with different learning rates, batch sizes, and optimizers (e.g., Adam, RMSprop, SGD) to find the combination that works best for your dataset.
Adjust the number of epochs: Sometimes, training for more epochs can lead to overfitting, while stopping too early can result in underfitting. Use techniques like early stopping to prevent overfitting.
-Data Augmentation:
Augment your dataset with variations of existing samples to increase robustness and generalization. Techniques like time shifting, adding noise, or pitch shifting can be effective for audio data.
Consider using techniques specific to audio data, such as time stretching, speed change, or frequency masking.
-Normalization:
Ensure proper normalization of input data. For audio data, mean normalization or standardization of MFCC features can be helpful.
-Evaluation Metrics:
Besides accuracy, consider using additional evaluation metrics such as precision, recall, F1-score, or area under the ROC curve (AUC) to get a better understanding of model performance, especially in imbalanced datasets.
-Model Interpretability:
Utilize techniques like gradient-weighted class activation mapping (Grad-CAM) or attention mechanisms to interpret the model's predictions and understand which parts of the input contribute most to the decision.
-Transfer Learning:
If you have limited data, consider using pre-trained models (e.g., on ImageNet) and fine-tuning them on your dataset. This approach can help leverage knowledge learned from large datasets.
Remember to experiment with these suggestions iteratively and monitor the performance changes. It's essential to strike a balance between model complexity and generalization to achieve the best results.
